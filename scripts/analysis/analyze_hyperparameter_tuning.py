"""
åˆ†æè¶…å‚æ•°è°ƒä¼˜ç»“æœå¹¶ä¸å†å²æ¨¡å‹å¯¹æ¯”
"""
import os
import json
import numpy as np

ROOT_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
RESULTS_DIR = os.path.join(ROOT_DIR, "results")

# åŠ è½½è¶…å‚æ•°è°ƒä¼˜ç»“æœ
tuning_file = os.path.join(RESULTS_DIR, "hyperparameter_tuning_results.json")
with open(tuning_file, 'r', encoding='utf-8') as f:
    tuning_data = json.load(f)

print("="*80)
print("ğŸ” è¶…å‚æ•°è°ƒä¼˜ç»“æœåˆ†æ")
print("="*80)

# æœ€ä½³é…ç½®
best_params = tuning_data['best_params']
best_loss = tuning_data['best_mean_val_loss']

print(f"\nâœ¨ æœ€ä½³è¶…å‚æ•°é…ç½® (æ¥è‡ª {tuning_data['total_trials']} æ¬¡è¯•éªŒ):")
print("-"*80)
for key, value in best_params.items():
    print(f"  {key:30} = {value}")
print(f"\n  {'æœ€ä½³å¹³å‡éªŒè¯æŸå¤±':30} = {best_loss:.8f}")

# Top 5 é…ç½®
print("\nğŸ“Š Top 5 æœ€ä½³é…ç½®:")
print("-"*80)
sorted_results = sorted(tuning_data['all_results'], key=lambda x: x['mean_val_loss'])

for i, res in enumerate(sorted_results[:5], 1):
    print(f"\n{i}. Mean Val Loss = {res['mean_val_loss']:.8f} (Â±{res['std_val_loss']:.8f})")
    for key, value in res['params'].items():
        print(f"   {key}: {value}")

# åŠ è½½å†å²è®­ç»ƒè®°å½•è¿›è¡Œå¯¹æ¯”
print("\n" + "="*80)
print("ğŸ“ˆ ä¸å†å²æ¨¡å‹å¯¹æ¯”")
print("="*80)

history_files = {
    'KæŠ˜+å¢å¼º+FPS (æ—§é…ç½®)': 'training_histories/training_history_kfold_aug_fps.json',
    'å•æ¬¡è®­ç»ƒ+å¢å¼º+FPS': 'training_histories/training_history_full_aug_fps.json',
    'æ—§KæŠ˜æ¨¡å‹ï¼ˆæ— å¢å¼ºï¼‰': 'training_histories/training_history_kfold.json'
}

comparison_data = []

for name, filepath in history_files.items():
    full_path = os.path.join(RESULTS_DIR, filepath)
    if not os.path.exists(full_path):
        continue
    
    with open(full_path, 'r', encoding='utf-8') as f:
        history = json.load(f)
    
    if 'statistics' in history:  # K-fold æ ¼å¼
        stats = history['statistics']
        mean_loss = stats.get('mean_best_val_loss', stats.get('mean_val_loss', 0))
        best_fold_loss = stats.get('best_fold_loss', 0)
        comparison_data.append({
            'name': name,
            'type': 'K-fold',
            'mean_val_loss': mean_loss,
            'best_val_loss': best_fold_loss
        })
    elif 'best_val_loss' in history:  # å•æ¬¡è®­ç»ƒæ ¼å¼
        best_loss_hist = history['best_val_loss']
        comparison_data.append({
            'name': name,
            'type': 'Single',
            'best_val_loss': best_loss_hist
        })

# æ·»åŠ è¶…å‚æ•°è°ƒä¼˜ç»“æœ
comparison_data.append({
    'name': 'è¶…å‚æ•°è°ƒä¼˜æœ€ä½³é…ç½®',
    'type': 'K-fold (Tuned)',
    'mean_val_loss': best_loss,
    'best_val_loss': min([res['mean_val_loss'] for res in tuning_data['all_results']])
})

print(f"\n{'æ¨¡å‹':<30} {'ç±»å‹':<20} {'æœ€ä½³éªŒè¯æŸå¤±':<20} {'æ”¹è¿›å¹…åº¦'}")
print("-"*100)

# æ‰¾åˆ°åŸºå‡†ï¼ˆæ—§KæŠ˜+å¢å¼º+FPSï¼‰
baseline = None
for item in comparison_data:
    if 'KæŠ˜+å¢å¼º+FPS' in item['name']:
        baseline = item['mean_val_loss'] if 'mean_val_loss' in item else item.get('best_val_loss', 0)
        break

for item in comparison_data:
    name = item['name']
    model_type = item['type']
    
    if 'mean_val_loss' in item:
        loss = item['mean_val_loss']
    else:
        loss = item['best_val_loss']
    
    if baseline and baseline > 0:
        improvement = ((baseline - loss) / baseline) * 100
        improvement_str = f"{improvement:+.2f}%"
    else:
        improvement_str = "N/A"
    
    print(f"{name:<30} {model_type:<20} {loss:<20.8f} {improvement_str}")

print("\n" + "="*80)
print("ğŸ’¡ ç»“è®º")
print("="*80)

if baseline:
    improvement = ((baseline - best_loss) / baseline) * 100
    print(f"\nâœ… è¶…å‚æ•°è°ƒä¼˜ä½¿ K æŠ˜éªŒè¯æŸå¤±æ”¹è¿›äº† {improvement:.2f}%")
    print(f"   ä» {baseline:.8f} â†’ {best_loss:.8f}")
else:
    print(f"\nâœ… è¶…å‚æ•°è°ƒä¼˜æ‰¾åˆ°æœ€ä½³é…ç½®ï¼ŒéªŒè¯æŸå¤±: {best_loss:.8f}")

print(f"\nğŸ¯ å…³é”®æ”¹è¿›:")
print(f"   - å­¦ä¹ ç‡è°ƒæ•´è‡³ {best_params['learning_rate']}")
print(f"   - Dropout å¢åŠ è‡³ {best_params['dropout_rate']} (é˜²æ­¢è¿‡æ‹Ÿåˆ)")
print(f"   - å­¦ä¹ ç‡è¡°å‡æ­¥é•¿ {best_params['lr_decay_step']} epochs")
print(f"   - Batch size = {best_params['batch_size']}")

print(f"\nğŸ“ å»ºè®®:")
print(f"   1. ä½¿ç”¨æœ€ä½³è¶…å‚æ•°é‡æ–°è®­ç»ƒå®Œæ•´æ¨¡å‹ï¼ˆæ›´å¤š epochsï¼Œå¦‚ 250-300ï¼‰")
print(f"   2. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ€§èƒ½ï¼ŒéªŒè¯æ³›åŒ–èƒ½åŠ›")
print(f"   3. å¦‚æœæ•ˆæœæ˜¾è‘—ï¼Œå¯ä½œä¸ºæœ€ç»ˆæ¨¡å‹")

print("\n" + "="*80)
